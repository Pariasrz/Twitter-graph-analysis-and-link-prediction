{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e39811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('twitter_graph.csv', header=None, names=['Follower','Target'])\n",
    "twitter_df.head(10)\n",
    "\n",
    "twitter_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4271b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 50 users with the highest number of followings\n",
    "F_vc = pd.DataFrame(twitter_df['Follower'].value_counts().iloc[:50])\n",
    "F_vc = F_vc.reset_index()\n",
    "F_vc['index'] = F_vc['index'].apply(lambda x:str(x))\n",
    "F_vc = F_vc.set_index('index')\n",
    "\n",
    "_, axes = plt.subplots(1,1, figsize=(6,4))\n",
    "#F_vc.plot() ;\n",
    "\n",
    "F_vc.plot(ax=axes, color='orangered')\n",
    "\n",
    "axes.set(xlabel=\"User id\", ylabel=\"Number of followings\")\n",
    "axes.set_title('Top 50 users with highest number of followings')\n",
    "axes.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_vc = pd.DataFrame(twitter_df['Target'].value_counts().iloc[:50])\n",
    "F_vc = F_vc.reset_index()\n",
    "F_vc['index'] = F_vc['index'].apply(lambda x:str(x))\n",
    "F_vc = F_vc.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 50 users with highest number of followers\n",
    "_, axes = plt.subplots(1,1, figsize=(6,4))\n",
    "#F_vc.plot() ;\n",
    "\n",
    "F_vc.plot(ax=axes, color='orangered')\n",
    "\n",
    "axes.set(xlabel=\"User id\", ylabel=\"Number of Followers\")\n",
    "axes.set_title('Top 50 users with highest number of followers')\n",
    "axes.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bd960",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(twitter_df, 'Follower', 'Target', create_using=nx.DiGraph())\n",
    "\n",
    "def plot_degree_dist(G):\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    plt.hist(degrees)\n",
    "    plt.show()\n",
    "\n",
    "plot_degree_dist(G)\n",
    "\n",
    "#a function to create a list of the frequency of each degree value.\n",
    "def degree_histogram_directed(G, in_degree=False, out_degree=False):\n",
    "    nodes = G.nodes()\n",
    "    if in_degree:\n",
    "        in_degree = dict(G.in_degree())\n",
    "        degseq=[in_degree.get(k,0) for k in nodes]\n",
    "    elif out_degree:\n",
    "        out_degree = dict(G.out_degree())\n",
    "        degseq=[out_degree.get(k,0) for k in nodes]\n",
    "    else:\n",
    "        degseq=[v for k, v in G.degree()]\n",
    "    dmax=max(degseq)+1\n",
    "    freq= [ 0 for d in range(dmax) ]\n",
    "    for d in degseq:\n",
    "        freq[d] += 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot in degree distribution\n",
    "in_degree_freq = degree_histogram_directed(G, in_degree=True)\n",
    "degrees = range(len(in_degree_freq))\n",
    "plt.figure(figsize=(6, 4)) \n",
    "plt.loglog(range(len(in_degree_freq)), in_degree_freq, 'o', label='in-degree',color='orangered',markersize=2) \n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb31cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot out degree distribution\n",
    "out_degree_freq = degree_histogram_directed(G, out_degree=True)\n",
    "degrees = range(len(in_degree_freq))\n",
    "plt.figure(figsize=(6, 4)) \n",
    "plt.loglog(range(len(out_degree_freq)), out_degree_freq, 'o', label='out-degree', color='orangered', markersize=2) \n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the graph so we don't have to re-run the code\n",
    "nx.write_gexf(G, \"test.gexf\")\n",
    "\n",
    "#graph statistics\n",
    "print(\"Number of nodes:\" , nx.number_of_nodes(G))\n",
    "print(\"Number of edgess:\" , nx.number_of_edges(G))\n",
    "#print(\"Degree distribution histogram\", nx.degree_histogram(G))\n",
    "#degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "print(\"Density\" , nx.density(G))\n",
    "print(\"Degree assortativity:\", nx.degree_assortativity_coefficient(G))\n",
    "print(\"Average Clustering Coefficient\", nx.average_clustering(G))\n",
    "print(\"Number of SCC\", nx.number_strongly_connected_components(G))\n",
    "print(\"Strongly connected components\", nx.strongly_connected_components(G))\n",
    "print(\"Number of WCC\", nx.number_weakly_connected_components(G))\n",
    "print(\"Weakly connected components\", nx.weakly_connected_components(G))\n",
    "print(\"average shortest path:\", nx.average_shortest_path_length(G))\n",
    "print(\"Diameter\", nx.diameter(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94263415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# read in your dataset\n",
    "df = pd.read_csv('twitter500.csv', header=None, names=['source', 'target', 'label'])\n",
    "#print(nx.degree(G)[12])\n",
    "# create a graph from the dataset\n",
    "G = nx.from_pandas_edgelist(df)\n",
    "\n",
    "# calculate degree centrality for each node in the graph\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "for i in df['source']:\n",
    "    df['source_degree'] = nx.degree(G)[i]\n",
    "\n",
    "for i in df['source']:\n",
    "    df['source_dc'] = nx.degree_centrality(G)[i]  \n",
    "    \n",
    "for i in df['target']:\n",
    "    df['target_degree'] = nx.degree(G)[i]\n",
    "\n",
    "for i in df['target']:\n",
    "    df['target_dc'] = nx.degree_centrality(G)[i] \n",
    "\n",
    "# calculate common neighbors for each edge and store in a new column\n",
    "df['common_neighbors'] = df.apply(lambda x: len(list(nx.common_neighbors(G, x['source'], x['target']))), axis=1)\n",
    "\n",
    "\n",
    "# save the updated DataFrame to a new CSV file\n",
    "df.to_csv('data_250.csv', index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['label']]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf647f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping target variables\n",
    "df = df.drop(['label'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb590b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.to_numpy()\n",
    "Y = target.to_numpy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "print ('Train set:', X_train.shape,  Y_train.shape)\n",
    "print ('Test set:', X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "#Neural Networks (MLP)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(random_state=0, max_iter=600).fit(X_train, Y_train)\n",
    "Y_pred = MLP.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=MLP.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "#Evaluation\n",
    "print(\"\\nMLP\")\n",
    "print('Confusion Matrix:' , cm)\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_pred)*100)\n",
    "print('Precision: ' , precision_score(Y_test, Y_pred)*100)\n",
    "print('Recall: ', recall_score(Y_test, Y_pred)*100)\n",
    "print('F-score: ' ,(f1_score(Y_test, Y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score , matthews_corrcoef\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "Y_pred = NB.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=NB.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "#Evaluation\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"\\n Naive Bayes\")\n",
    "print('Confusion Matrix:', cm)\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_pred)*100)\n",
    "print('Precision: ' , precision_score(Y_test, Y_pred)*100)\n",
    "print('Recall: ', recall_score(Y_test, Y_pred)*100)\n",
    "print('F-score: ' ,(f1_score(Y_test, Y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef \n",
    "\n",
    "#K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors = 100, metric='euclidean').fit(X_train, Y_train)\n",
    "Y_pred = KNN.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=KNN.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "#Evaluation\n",
    "print(\"\\nK Nearest Neighbors\")\n",
    "print('Confusion Matrix:' , cm)\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_pred)*100)\n",
    "print('Precision: ' , precision_score(Y_test, Y_pred)*100)\n",
    "print('Recall: ', recall_score(Y_test, Y_pred)*100)\n",
    "print('F-score: ' ,(f1_score(Y_test, Y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators= 100).fit(X_train, Y_train)\n",
    "Y_pred = RF.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=RF.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "#Evaluation\n",
    "print(\"\\nRandom Forest\")\n",
    "print('Confusion Matrix:' , cm)\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_pred)*100)\n",
    "print('Precision: ' , precision_score(Y_test, Y_pred)*100)\n",
    "print('Recall: ', recall_score(Y_test, Y_pred)*100)\n",
    "print('F-score: ' ,(f1_score(Y_test, Y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
